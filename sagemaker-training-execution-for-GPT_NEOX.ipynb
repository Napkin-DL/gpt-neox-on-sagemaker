{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SageMaker Training job execution for GPT-NEOX\n",
    "---\n",
    "\n",
    "본 모듈에서는 Amzaon SageMaker API을 효과적으로 이용하기 위해 multigpu-distributed 학습을 위한 PyTorch 프레임워크 자체 구현만으로 모델 훈련을 수행해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_needed = True  # should only be True once\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "#     !{sys.executable} -m pip install -U split-folders tqdm albumentations crc32c wget\n",
    "    !{sys.executable} -m pip install 'sagemaker[local]' --upgrade\n",
    "    !{sys.executable} -m pip install -U smdebug sagemaker-experiments\n",
    "    !{sys.executable} -m pip install -U sagemaker\n",
    "    !{sys.executable} -m pip install -U lm_dataformat ftfy deepspeed\n",
    "    !/bin/bash ./local/local_change_setting.sh\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 환경 설정\n",
    "\n",
    "<p>Sagemaker 학습에 필요한 기본적인 package를 import 합니다. </p>\n",
    "<p>boto3는 HTTP API 호출을 숨기는 편한 추상화 모델을 가지고 있고, Amazon EC2 인스턴스 및 S3 버켓과 같은 AWS 리소스와 동작하는 파이선 클래스를 제공합니다. </p>\n",
    "<p>sagemaker python sdk는 Amazon SageMaker에서 기계 학습 모델을 교육 및 배포하기 위한 오픈 소스 라이브러리입니다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import sagemaker\n",
    "# import splitfolders\n",
    "\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "\n",
    "# import wget\n",
    "# import tarfile\n",
    "import shutil\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from time import strftime\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "from sagemaker.debugger import (Rule,\n",
    "                                rule_configs,\n",
    "                                ProfilerConfig, \n",
    "                                FrameworkProfile, \n",
    "                                DetailedProfilingConfig, \n",
    "                                DataloaderProfilingConfig, \n",
    "                                PythonProfilingConfig)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# rm -rf ./data\n",
    "# cd ./gpt-neox\n",
    "# python prepare_data.py -d ../data\n",
    "# aws s3 sync ../data s3://dataset-us-west-2-cyj/gpt_neox_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name):\n",
    "    try:\n",
    "        sm_experiment = Experiment.load(experiment_name)\n",
    "    except:\n",
    "        sm_experiment = Experiment.create(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trial(experiment_name, i_type, i_cnt):\n",
    "    create_date = strftime(\"%m%d-%H%M%s\")\n",
    "\n",
    "    i_tag = 'test'\n",
    "    if i_type == 'ml.p4d.24xlarge':\n",
    "        i_tag = 'p4d'    \n",
    "        \n",
    "    trial = \"-\".join([i_tag,str(i_cnt)])\n",
    "       \n",
    "    sm_trial = Trial.create(trial_name=f'{experiment_name}-{trial}-{create_date}',\n",
    "                            experiment_name=experiment_name)\n",
    "\n",
    "    job_name = f'{sm_trial.trial_name}'\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'gpt-neox-sagemaker-220308'\n",
    "code_location = f's3://{bucket}/backup_codes'\n",
    "output_path = f's3://{bucket}/gpt_neox_output' \n",
    "s3_log_path = f's3://{bucket}/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "#      {'Name': 'train:lr', 'Regex': 'lr - (.*?),'},\n",
    "#      {'Name': 'train:Loss', 'Regex': 'loss -(.*?),'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"d\": \"configs\",\n",
    "    \"conf_file\" : \"small.yml sm_local_setup.yml\"\n",
    "    }\n",
    "\n",
    "\n",
    "experiment_name = 'gpt-neox-exp1'\n",
    "instance_type = 'ml.p4d.24xlarge'  # 'ml.p3.16xlarge', 'ml.p3dn.24xlarge', 'ml.p4d.24xlarge', 'local_gpu'\n",
    "# instance_type = 'local_gpu'\n",
    "instance_count = 1\n",
    "do_spot_training = False\n",
    "max_wait = None\n",
    "max_run = 4*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if instance_type =='local_gpu':\n",
    "    from sagemaker.local import LocalSession\n",
    "    from pathlib import Path\n",
    "\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    s3_data_path = f'file://{Path.cwd()}/data'\n",
    "    source_dir = f'{Path.cwd()}/gpt-neox'\n",
    "    checkpoint_s3_uri = None\n",
    "else:\n",
    "    sess = boto3.Session()\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    sm = sess.client('sagemaker')\n",
    "    s3_data_path = 's3://dataset-us-west-2-cyj/gpt_neox_dataset'\n",
    "    source_dir = 'gpt-neox'\n",
    "    checkpoint_s3_uri = f's3://{bucket}/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = {}\n",
    "flag = 'deepspeed'\n",
    "\n",
    "if flag == 'smddp':\n",
    "    distribution[\"smdistributed\"]={ \n",
    "                        \"dataparallel\": {\n",
    "                            \"enabled\": True\n",
    "                        }\n",
    "                }\n",
    "\n",
    "elif flag == 'smmp':\n",
    "    distribution['smdistributed'] = {\n",
    "        \"modelparallel\": {\n",
    "            \"enabled\":True,\n",
    "            \"parameters\": {\n",
    "                \"ddp\": True,\n",
    "                \"tensor_parallel_degree\": hyperparameters['tensor_parallel_degree'],\n",
    "                # partitions is a required param in the current SM SDK so it needs to be passed,\n",
    "                # these two map to the same config\n",
    "                \"partitions\": hyperparameters['pipeline_parallel_degree'],\n",
    "                \"shard_optimizer_state\": hyperparameters['shard_optimizer_state'] > 0,\n",
    "                \"prescaled_batch\": hyperparameters['prescaled_batch'] > 0,\n",
    "                \"fp16_params\": hyperparameters['fp16'] > 0,\n",
    "                \"optimize\": hyperparameters['optimize'],\n",
    "                \"auto_partition\": True,\n",
    "                \"default_partition\": 0,                        \n",
    "                \"fp16_params\": hyperparameters['fp16'] > 0,\n",
    "                \"optimize\": hyperparameters['optimize'],\n",
    "            }\n",
    "        }   \n",
    "    }\n",
    "    mpioptions = \"-x NCCL_DEBUG=WARN -x SMDEBUG_LOG_LEVEL=ERROR \"\n",
    "    mpioptions += \"-x SMP_DISABLE_D2D=1 -x SMP_D2D_GPU_BUFFER_SIZE_BYTES=1 -x SMP_NCCL_THROTTLE_LIMIT=1 \"\n",
    "    mpioptions += \"-x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1\"\n",
    "\n",
    "    metric_definitions = [{\"Name\": \"base_metric\", \"Regex\": \"<><><><><><>\"}] # Add your custom metric definitions\n",
    "\n",
    "    distribution[\"mpi\"]={\n",
    "        \"enabled\": True,\n",
    "        \"processes_per_host\": 8, # Pick your processes_per_host\n",
    "        \"custom_mpi_options\": mpioptions      \n",
    "    }\n",
    "else:\n",
    "    distribution[\"mpi\"]={\"enabled\": True}\n",
    "\n",
    "if do_spot_training:\n",
    "    max_wait = max_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point='sm_train.py',\n",
    "    source_dir=source_dir,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version='1.9',\n",
    "    py_version='py38',\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "#     volume_size=1024,\n",
    "    code_location = code_location,\n",
    "    output_path=output_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution=distribution,\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    "    metric_definitions=metric_definitions,\n",
    "#     rules=rules,\n",
    "    max_run=max_run,\n",
    "    use_spot_instances=do_spot_training,  # spot instance 활용\n",
    "    max_wait=max_wait,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo rm -rf ./gpt-neox/core*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name, instance_type, instance_count)\n",
    "\n",
    "estimator.fit(\n",
    "    inputs={'training': s3_data_path}, \n",
    "    job_name=job_name,\n",
    "    experiment_config={\n",
    "      'TrialName': job_name,\n",
    "      'TrialComponentDisplayName': job_name,\n",
    "    },\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name=estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
